{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_z2fw17x",
    "id": "64AE0FB342E9428A8DA9C734B357BBB1",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# softmax和分类模型\n",
    "内容包含：\n",
    "1. softmax回归的基本概念\n",
    "2. 如何获取Fashion-MNIST数据集和读取数据\n",
    "3. softmax回归模型的从零开始实现，实现一个对Fashion-MNIST训练集中的图像数据进行分类的模型\n",
    "4. 使用pytorch重新实现softmax回归模型\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_xq1py16",
    "id": "2031A689D83B4282ABA8CC2238D7FC9B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## softmax的基本概念\n",
    "\n",
    "- 分类问题  \n",
    "一个简单的图像分类问题，输入图像的高和宽均为2像素，色彩为灰度。  \n",
    "图像中的4像素分别记为$x_1, x_2, x_3, x_4$。  \n",
    "假设真实标签为狗、猫或者鸡，这些标签对应的离散值为$y_1, y_2, y_3$。  \n",
    "我们通常使用离散的数值来表示类别，例如$y_1=1, y_2=2, y_3=3$。\n",
    "\n",
    "- 权重矢量  \n",
    "$$\n",
    " \\begin{aligned} o_1 &= x_1 w_{11} + x_2 w_{21} + x_3 w_{31} + x_4 w_{41} + b_1 \\end{aligned} \n",
    "$$\n",
    "\n",
    "$$\n",
    " \\begin{aligned} o_2 &= x_1 w_{12} + x_2 w_{22} + x_3 w_{32} + x_4 w_{42} + b_2 \\end{aligned} \n",
    "$$\n",
    "\n",
    "$$\n",
    " \\begin{aligned} o_3 &= x_1 w_{13} + x_2 w_{23} + x_3 w_{33} + x_4 w_{43} + b_3 \\end{aligned} \n",
    "$$\n",
    "\n",
    "- 神经网络图  \n",
    "下图用神经网络图描绘了上面的计算。softmax回归同线性回归一样，也是一个单层神经网络。由于每个输出$o_1, o_2, o_3$的计算都要依赖于所有的输入$x_1, x_2, x_3, x_4$，softmax回归的输出层也是一个全连接层。\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}softmax回归是一个单层神经网络\\end{aligned}\n",
    "$$\n",
    "\n",
    "既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值$o_i$当作预测类别是$i$的置信度，并将值最大的输出所对应的类作为预测输出，即输出 $\\underset{i}{\\arg\\max} o_i$。例如，如果$o_1,o_2,o_3$分别为$0.1,10,0.1$，由于$o_2$最大，那么预测类别为2，其代表猫。\n",
    "\n",
    "- 输出问题  \n",
    "直接使用输出层的输出有两个问题：\n",
    "    1. 一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果$o_1=o_3=10^3$，那么输出值10却又表示图像类别为猫的概率很低。\n",
    "    2. 另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。\n",
    "\n",
    "softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：\n",
    "\n",
    "$$\n",
    " \\hat{y}_1, \\hat{y}_2, \\hat{y}_3 = \\text{softmax}(o_1, o_2, o_3) \n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    " \\hat{y}1 = \\frac{ \\exp(o_1)}{\\sum_{i=1}^3 \\exp(o_i)},\\quad \\hat{y}2 = \\frac{ \\exp(o_2)}{\\sum_{i=1}^3 \\exp(o_i)},\\quad \\hat{y}3 = \\frac{ \\exp(o_3)}{\\sum_{i=1}^3 \\exp(o_i)}. \n",
    "$$\n",
    "\n",
    "容易看出$\\hat{y}_1 + \\hat{y}_2 + \\hat{y}_3 = 1$且$0 \\leq \\hat{y}_1, \\hat{y}_2, \\hat{y}_3 \\leq 1$，因此$\\hat{y}_1, \\hat{y}_2, \\hat{y}_3$是一个合法的概率分布。这时候，如果$\\hat{y}_2=0.8$，不管$\\hat{y}_1$和$\\hat{y}_3$的值是多少，我们都知道图像类别为猫的概率是80%。此外，我们注意到\n",
    "\n",
    "$$\n",
    " \\underset{i}{\\arg\\max} o_i = \\underset{i}{\\arg\\max} \\hat{y}_i \n",
    "$$\n",
    "\n",
    "因此softmax运算不改变预测类别输出。\n",
    "\n",
    "- 计算效率\n",
    "    - 单样本矢量计算表达式  \n",
    "    为了提高计算效率，我们可以将单样本分类通过矢量计算来表达。在上面的图像分类问题中，假设softmax回归的权重和偏差参数分别为\n",
    "   \n",
    "$$\n",
    " \\boldsymbol{W} = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\\\ w_{31} & w_{32} & w_{33} \\\\ w_{41} & w_{42} & w_{43} \\end{bmatrix},\\quad \\boldsymbol{b} = \\begin{bmatrix} b_1 & b_2 & b_3 \\end{bmatrix}, \n",
    "$$\n",
    "\n",
    "设高和宽分别为2个像素的图像样本$i$的特征为\n",
    "   \n",
    "$$\n",
    "\\boldsymbol{x}^{(i)} = \\begin{bmatrix}x_1^{(i)} & x_2^{(i)} & x_3^{(i)} & x_4^{(i)}\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "输出层的输出为\n",
    "\n",
    "$$\n",
    "\\boldsymbol{o}^{(i)} = \\begin{bmatrix}o_1^{(i)} & o_2^{(i)} & o_3^{(i)}\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "预测为狗、猫或鸡的概率分布为\n",
    "    \n",
    "$$\n",
    "\\boldsymbol{\\hat{y}}^{(i)} = \\begin{bmatrix}\\hat{y}_1^{(i)} & \\hat{y}_2^{(i)} & \\hat{y}_3^{(i)}\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "softmax回归对样本$i$分类的矢量计算表达式为\n",
    "   \n",
    "$$\n",
    " \\begin{aligned} \\boldsymbol{o}^{(i)} &= \\boldsymbol{x}^{(i)} \\boldsymbol{W} + \\boldsymbol{b},\\\\ \\boldsymbol{\\hat{y}}^{(i)} &= \\text{softmax}(\\boldsymbol{o}^{(i)}). \\end{aligned} \n",
    "$$\n",
    "\n",
    "- 小批量矢量计算表达式  \n",
    "    为了进一步提升计算效率，我们通常对小批量数据做矢量计算。广义上讲，给定一个小批量样本，其批量大小为$n$，输入个数（特征数）为$d$，输出个数（类别数）为$q$。设批量特征为$\\boldsymbol{X} \\in \\mathbb{R}^{n \\times d}$。假设softmax回归的权重和偏差参数分别为$\\boldsymbol{W} \\in \\mathbb{R}^{d \\times q}$和$\\boldsymbol{b} \\in \\mathbb{R}^{1 \\times q}$。softmax回归的矢量计算表达式为\n",
    "\n",
    "$$\n",
    " \\begin{aligned} \\boldsymbol{O} &= \\boldsymbol{X} \\boldsymbol{W} + \\boldsymbol{b},\\\\ \\boldsymbol{\\hat{Y}} &= \\text{softmax}(\\boldsymbol{O}), \\end{aligned} \n",
    "$$\n",
    "\n",
    "其中的加法运算使用了广播机制，$\\boldsymbol{O}, \\boldsymbol{\\hat{Y}} \\in \\mathbb{R}^{n \\times q}$且这两个矩阵的第$i$行分别为样本$i$的输出$\\boldsymbol{o}^{(i)}$和概率分布$\\boldsymbol{\\hat{y}}^{(i)}$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "900A996DF3114CBE8545153F973B4640",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 交叉熵损失函数\n",
    "\n",
    "对于样本$i$，我们构造向量$\\boldsymbol{y}^{(i)}\\in \\mathbb{R}^{q}$ ，使其第$y^{(i)}$（样本$i$类别的离散数值）个元素为1，其余为0。这样我们的训练目标可以设为使预测概率分布$\\boldsymbol{\\hat y}^{(i)}$尽可能接近真实的标签概率分布$\\boldsymbol{y}^{(i)}$。\n",
    "\n",
    "- 平方损失估计  \n",
    "\n",
    "$$\n",
    "\\begin{aligned}Loss = |\\boldsymbol{\\hat y}^{(i)}-\\boldsymbol{y}^{(i)}|^2/2\\end{aligned}\n",
    "$$\n",
    "  \n",
    "\n",
    "然而，想要预测分类结果正确，我们其实并不需要预测概率完全等于标签概率。例如，在图像分类的例子里，如果$y^{(i)}=3$，那么我们只需要$\\hat{y}^{(i)}_3$比其他两个预测值$\\hat{y}^{(i)}_1$和$\\hat{y}^{(i)}_2$大就行了。即使$\\hat{y}^{(i)}_3$值为0.6，不管其他两个预测值为多少，类别预测均正确。而平方损失则过于严格，例如$\\hat y^{(i)}_1=\\hat y^{(i)}_2=0.2$比$\\hat y^{(i)}_1=0, \\hat y^{(i)}_2=0.4$的损失要小很多，虽然两者都有同样正确的分类预测结果。\n",
    "\n",
    "改善上述问题的一个方法是使用更适合衡量两个概率分布差异的测量函数。其中，交叉熵（cross entropy）是一个常用的衡量方法：\n",
    "\n",
    "\n",
    "$$\n",
    "H\\left(\\boldsymbol y^{(i)}, \\boldsymbol {\\hat y}^{(i)}\\right ) = -\\sum_{j=1}^q y_j^{(i)} \\log \\hat y_j^{(i)},\n",
    "$$\n",
    "\n",
    "\n",
    "其中带下标的$y_j^{(i)}$是向量$\\boldsymbol y^{(i)}$中非0即1的元素，需要注意将它与样本$i$类别的离散数值，即不带下标的$y^{(i)}$区分。在上式中，我们知道向量$\\boldsymbol y^{(i)}$中只有第$y^{(i)}$个元素$y^{(i)}{y^{(i)}}$为1，其余全为0，于是$H(\\boldsymbol y^{(i)}, \\boldsymbol {\\hat y}^{(i)}) = -\\log \\hat y{y^{(i)}}^{(i)}$。也就是说，交叉熵只关心对正确类别的预测概率，因为只要其值足够大，就可以确保分类结果正确。当然，遇到一个样本有多个标签时，例如图像里含有不止一个物体时，我们并不能做这一步简化。但即便对于这种情况，交叉熵同样只关心对图像中出现的物体类别的预测概率。\n",
    "\n",
    "假设训练数据集的样本数为$n$，交叉熵损失函数定义为 \n",
    "$$\n",
    "\\ell(\\boldsymbol{\\Theta}) = \\frac{1}{n} \\sum_{i=1}^n H\\left(\\boldsymbol y^{(i)}, \\boldsymbol {\\hat y}^{(i)}\\right ),\n",
    "$$\n",
    "\n",
    "\n",
    "其中$\\boldsymbol{\\Theta}$代表模型参数。同样地，如果每个样本只有一个标签，那么交叉熵损失可以简写成$\\ell(\\boldsymbol{\\Theta}) = -(1/n) \\sum_{i=1}^n \\log \\hat y_{y^{(i)}}^{(i)}$。从另一个角度来看，我们知道最小化$\\ell(\\boldsymbol{\\Theta})$等价于最大化$\\exp(-n\\ell(\\boldsymbol{\\Theta}))=\\prod_{i=1}^n \\hat y_{y^{(i)}}^{(i)}$，即最小化交叉熵损失函数等价于最大化训练数据集所有标签类别的联合预测概率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9221297B8C694D4F9B76FDFD29C02E5E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 模型训练和预测\n",
    "在训练好softmax回归模型后，给定任一样本特征，就可以预测每个输出类别的概率。通常，我们把预测概率最大的类别作为输出类别。如果它与真实类别（标签）一致，说明这次预测是正确的。在3.6节的实验中，我们将使用准确率（accuracy）来评价模型的表现。它等于正确预测数量与总预测数量之比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_co5e0yp",
    "id": "3D1A30145B5A450E819DCA2FB094117B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 获取Fashion-MNIST训练集和读取数据\n",
    "在介绍softmax回归的实现前我们先引入一个多类图像分类数据集。它将在后面的章节中被多次使用，以方便我们观察比较算法之间在模型精度和计算效率上的区别。图像分类数据集中最常用的是手写数字识别数据集MNIST[1]。但大部分模型在MNIST上的分类精度都超过了95%。为了更直观地观察算法之间的差异，我们将使用一个图像内容更加复杂的数据集Fashion-MNIST[2]。\n",
    "\n",
    "我这里我们会使用torchvision包，它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：\n",
    "1. torchvision.datasets: 一些加载数据的函数及常用的数据集接口；\n",
    "2. torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；\n",
    "3. torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；\n",
    "4. torchvision.utils: 其他的一些有用的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "graffitiCellId": "id_my8ejol",
    "id": "9C804F2DABDA482BB4375CB0D36E011D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e3b06ab588d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# import needed package\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input\")\n",
    "import d2lzh1981 as d2l\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_75u5u2k",
    "id": "810E6357484047F08D83319B46F7438F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "graffitiCellId": "id_no4tgy0",
    "id": "6FF62DC73B1D46128E613FC7DFFB3C3C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root='/home/kesci/input/FashionMNIST2065', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='/home/kesci/input/FashionMNIST2065', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_mekh927",
    "id": "DD5743BBD5614F49829E2AA08F422D77",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "class torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
    "- root（string）– 数据集的根目录，其中存放processed/training.pt和processed/test.pt文件。\n",
    "- train（bool, 可选）– 如果设置为True，从training.pt创建数据集，否则从test.pt创建。\n",
    "- download（bool, 可选）– 如果设置为True，从互联网下载数据并放到root文件夹下。如果root目录下已经存在数据，不会再次下载。\n",
    "- transform（可被调用 , 可选）– 一种函数或变换，输入PIL图片，返回变换之后的数据。如：transforms.RandomCrop。\n",
    "- target_transform（可被调用 , 可选）– 一种函数或变换，输入目标，进行变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "graffitiCellId": "id_d4dkkil",
    "id": "B4B6EB3C4CF74C1D8034A9A349870804",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# show result \n",
    "print(type(mnist_train))\n",
    "print(len(mnist_train), len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "graffitiCellId": "id_yndoddn",
    "id": "E35B37B4A94A44AA89722155E8AB5788",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "# 我们可以通过下标来访问任意一个样本\n",
    "feature, label = mnist_train[0]\n",
    "print(feature.shape, label)  # Channel x Height x Width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_lkp5d0p",
    "id": "AFC6C721591743D789E443EE6637458E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "如果不做变换输入的数据是图像，我们可以看一下图片的类型参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "graffitiCellId": "id_2dk2d0m",
    "id": "C72CDF6B5BA64F36AAB028CFCB1242C9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=28x28 at 0x7F57E8736F28>\n"
     ]
    }
   ],
   "source": [
    "mnist_PIL = torchvision.datasets.FashionMNIST(root='/home/kesci/input/FashionMNIST2065', train=True, download=True)\n",
    "PIL_feature, label = mnist_PIL[0]\n",
    "print(PIL_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "graffitiCellId": "id_pku7gp5",
    "id": "B7454582B1484EE4B227BF145B0ED3BA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh包中方便以后使用\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "graffitiCellId": "id_1x2gagm",
    "id": "D241CBCCD1CD47F28B9480080B93D4FD",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    d2l.use_svg_display()\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "graffitiCellId": "id_us9fuso",
    "id": "056F457B00454FFD81A3CB6AD966C508",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/056F457B00454FFD81A3CB6AD966C508/q5htpkvjtx.svg\">"
      ],
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = [], []\n",
    "for i in range(10):\n",
    "    X.append(mnist_train[i][0]) # 将第i个feature加到X中\n",
    "    y.append(mnist_train[i][1]) # 将第i个label加到y中\n",
    "show_fashion_mnist(X, get_fashion_mnist_labels(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "graffitiCellId": "id_uy1hu22",
    "id": "34AD2BCBAD9149428E1C29B6F5530BAC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "graffitiCellId": "id_2vdyxtx",
    "id": "2A439C938A5B43449F0160F5DACB4759",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for X, y in train_iter:\n",
    "    continue\n",
    "print('%.2f sec' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0nzlmif",
    "id": "7886893A27B44B979B7E4B93F870B3CE",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# softmax从零开始的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "graffitiCellId": "id_c0aor6l",
    "id": "C47E4519B73C46558F23670B6C6D2CF4",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "0.4.1a0+d94043a\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input\")\n",
    "import d2lzh1981 as d2l\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_63x3cw1",
    "id": "24E441B54DB5429991AC9DEBB6014FEC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 获取训练集数据和测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "graffitiCellId": "id_lkxl1n6",
    "id": "39EFD4C2466B4A649B15C7535800FAD6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_h6qpe01",
    "id": "7DC915895B5C46278F4C395BD49815A0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 模型参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "graffitiCellId": "id_xcafpiw",
    "id": "FD4BCCEF1A044DF99791FB17D8134B6A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "print(28*28)\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float)\n",
    "b = torch.zeros(num_outputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "graffitiCellId": "id_1ow0q3n",
    "id": "D5372FA087BA4BAF87E940582444FB2D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_d5s0vs0",
    "id": "3BBF52F8DB29448B9D44F5D707596788",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 对多维Tensor按维度操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "graffitiCellId": "id_e13vki6",
    "id": "6BFBFFFB54E44D05B1FC16BE841BB815",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9]])\n",
      "tensor([[ 6],\n",
      "        [15]])\n",
      "tensor([5, 7, 9])\n",
      "tensor([ 6, 15])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(X.sum(dim=0, keepdim=True))  # dim为0，按照相同的列求和，并在结果中保留列特征\n",
    "print(X.sum(dim=1, keepdim=True))  # dim为1，按照相同的行求和，并在结果中保留行特征\n",
    "print(X.sum(dim=0, keepdim=False)) # dim为0，按照相同的列求和，不在结果中保留列特征\n",
    "print(X.sum(dim=1, keepdim=False)) # dim为1，按照相同的行求和，不在结果中保留行特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_fn39y6u",
    "id": "F15E94B777BA4E9F88CB18BD16697A45",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义softmax操作\n",
    "\n",
    "$$\n",
    " \\hat{y}_j = \\frac{ \\exp(o_j)}{\\sum_{i=1}^3 \\exp(o_i)} \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "graffitiCellId": "id_cr8iqvr",
    "id": "7F882A63347F46318C5F334F4F55F123",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    # print(\"X size is \", X_exp.size())\n",
    "    # print(\"partition size is \", partition, partition.size())\n",
    "    return X_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "graffitiCellId": "id_vxj92pl",
    "id": "A77A982B8916433AAB521914CFD8467D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1927, 0.2009, 0.1823, 0.1887, 0.2355],\n",
      "        [0.1274, 0.1843, 0.2536, 0.2251, 0.2096]]) \n",
      " tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2, 5))\n",
    "X_prob = softmax(X)\n",
    "print(X_prob, '\\n', X_prob.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_bkbmqh1",
    "id": "F59CC29AE6F5407A84064647281E9ECA",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## softmax回归模型\n",
    " \n",
    "$$\n",
    " \\begin{aligned} \\boldsymbol{o}^{(i)} &= \\boldsymbol{x}^{(i)} \\boldsymbol{W} + \\boldsymbol{b},\\\\ \\boldsymbol{\\hat{y}}^{(i)} &= \\text{softmax}(\\boldsymbol{o}^{(i)}). \\end{aligned} \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "graffitiCellId": "id_76a2fpk",
    "id": "0B3F76DCDD23439D849A2AE842D7DBE5",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9kc1jw8",
    "id": "5024E97053FF460A8CB5F2FCC75C0C27",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义损失函数\n",
    "\n",
    "$$\n",
    "H\\left(\\boldsymbol y^{(i)}, \\boldsymbol {\\hat y}^{(i)}\\right ) = -\\sum_{j=1}^q y_j^{(i)} \\log \\hat y_j^{(i)},\n",
    "$$\n",
    "  \n",
    "\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\Theta}) = \\frac{1}{n} \\sum_{i=1}^n H\\left(\\boldsymbol y^{(i)}, \\boldsymbol {\\hat y}^{(i)}\\right ),\n",
    "$$\n",
    "  \n",
    "\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\Theta}) = -(1/n) \\sum_{i=1}^n \\log \\hat y_{y^{(i)}}^{(i)}\n",
    "$$\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "graffitiCellId": "id_fl3cdvq",
    "id": "0244A13F3B4F43EA9B8D2FC5800238C7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.5000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = torch.LongTensor([0, 2])\n",
    "y_hat.gather(1, y.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "graffitiCellId": "id_4ymtpzn",
    "id": "D288CFCAE8DF464287ECA08AD5168F2E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_epbrym1",
    "id": "83DD3AF7D13F489D8683CB751F430CBF",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义准确率\n",
    "    我们模型训练完了进行模型预测的时候，会用到我们这里定义的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "graffitiCellId": "id_8h5q5ic",
    "id": "B82A0C9B1F984CF089B9FA8747BE1A3B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "graffitiCellId": "id_2szlvh2",
    "id": "9A6EF0B8618B400D8D252223B6B04E2D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "graffitiCellId": "id_gtpf1ob",
    "id": "963FEE28FD23446895193E95A4915F2A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中描述\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "graffitiCellId": "id_90h5xb7",
    "id": "BDDE1D7C593D47B78465BA7E4F991B82",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1457\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_accuracy(test_iter, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_1p8f5ji",
    "id": "A209780170A64CC29271427320284785",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "graffitiCellId": "id_smslnb6",
    "id": "EFDCDFDDE4B44FA3866BEABC48F44D57",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7870, train acc 0.751, test acc 0.794\n",
      "epoch 2, loss 0.5702, train acc 0.813, test acc 0.809\n",
      "epoch 3, loss 0.5254, train acc 0.826, test acc 0.814\n",
      "epoch 4, loss 0.5009, train acc 0.832, test acc 0.822\n",
      "epoch 5, loss 0.4853, train acc 0.837, test acc 0.828\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                d2l.sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step() \n",
    "            \n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_eptwt05",
    "id": "D7885C25CD7444BF8212D2102E99692C",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 模型预测\n",
    "现在我们的模型训练完了，可以进行一下预测，我们的这个模型训练的到底准确不准确。\n",
    "现在就可以演示如何对图像进行分类了。给定一系列图像（第三行图像输出），我们比较一下它们的真实标签（第一行文本输出）和模型预测结果（第二行文本输出）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "graffitiCellId": "id_yt8sd9t",
    "id": "1DA8927186304BEBA2B3DCC4A9E027DD",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/1DA8927186304BEBA2B3DCC4A9E027DD/q5htqja8gy.svg\">"
      ],
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = iter(test_iter).next()\n",
    "\n",
    "true_labels = d2l.get_fashion_mnist_labels(y.numpy())\n",
    "pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())\n",
    "titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
    "\n",
    "d2l.show_fashion_mnist(X[0:9], titles[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_623cj7f",
    "id": "740E43F6246C47078E68E5EB4399345A",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# softmax的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "graffitiCellId": "id_s0m2c8a",
    "id": "94B0411C93ED4E6C83B5545D9339E395",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "# 加载各种包或者模块\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/kesci/input\")\n",
    "import d2lzh1981 as d2l\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_7ny2q9r",
    "id": "21E9BF3FC62E42FAA0D601526BC27572",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 初始化参数和获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "graffitiCellId": "id_3ra54mv",
    "id": "08E33ED9A5684635874D11BFC0B488C6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_pvkd7mm",
    "id": "7BCB961EF5464E1980619F1853FE2F84",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "graffitiCellId": "id_1s76ktf",
    "id": "01609B4BD2B444588B2C33751B48B9B0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "    def forward(self, x): # x 的形状: (batch, 1, 28, 28)\n",
    "        y = self.linear(x.view(x.shape[0], -1))\n",
    "        return y\n",
    "    \n",
    "# net = LinearNet(num_inputs, num_outputs)\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x 的形状: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(\n",
    "        # FlattenLayer(),\n",
    "        # LinearNet(num_inputs, num_outputs) \n",
    "        OrderedDict([\n",
    "           ('flatten', FlattenLayer()),\n",
    "           ('linear', nn.Linear(num_inputs, num_outputs))]) # 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_nssr12v",
    "id": "1C3A731775674DDFB88CA79FBCFABCFC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "graffitiCellId": "id_id7oqtn",
    "id": "444F87CD78CC4DCE9E76E56B9D096E48",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.normal_(net.linear.weight, mean=0, std=0.01)\n",
    "init.constant_(net.linear.bias, val=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_hn4au8n",
    "id": "EC61B11479EA443E812CCF03CC85D871",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "graffitiCellId": "id_knh2n50",
    "id": "EFA9FA88D866458F913194664286D8AB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() # 下面是他的函数原型\n",
    "# class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_bdskdx7",
    "id": "FFD0D8B3BB1B4F6582610743373C576E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "graffitiCellId": "id_6l357pq",
    "id": "7DF366DFD7D349B59B0CA9D3211EB140",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1) # 下面是函数原型\n",
    "# class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_kzma3d6",
    "id": "6A660AA6E71541EA85B4955AC0DCC66C",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "graffitiCellId": "id_0puuqtc",
    "id": "A49C9427C0E14DB9914E8970D98C422B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0031, train acc 0.749, test acc 0.794\n",
      "epoch 2, loss 0.0022, train acc 0.814, test acc 0.800\n",
      "epoch 3, loss 0.0021, train acc 0.826, test acc 0.811\n",
      "epoch 4, loss 0.0020, train acc 0.833, test acc 0.826\n",
      "epoch 5, loss 0.0019, train acc 0.837, test acc 0.825\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
